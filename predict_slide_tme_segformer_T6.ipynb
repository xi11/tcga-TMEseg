{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d47b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 20:36:14.372613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.372828: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.401418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.401617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.401790: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.401955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.531704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.531898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.532067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.532229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.532408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.532571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.551303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.551496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.551672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.551838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.552004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.552160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22266 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2024-03-11 20:36:14.552534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:36:14.552687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22198 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "All model checkpoint layers were used when initializing TFSegformerForSemanticSegmentation.\n",
      "\n",
      "All the layers of TFSegformerForSemanticSegmentation were initialized from the model checkpoint at /rsrch5/home/trans_mol_path/xpan7/pipelines/TMEseg_tcga/model/mit-b3-finetuned-tmeTCGA-60-lr00001-s512-20x768.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFSegformerForSemanticSegmentation for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NS003-La.svs\n",
      "Already Processed /rsrch6/home/trans_mol_path/yuan_lab/TIER2/anthracosis/never_smoker_multi/mit-b3-finetuned-tmeTCGA-60-lr00001-s512-20x768/mask_cws/NS003-La.svs/Da0.png\n",
      "\n",
      "Already Processed /rsrch6/home/trans_mol_path/yuan_lab/TIER2/anthracosis/never_smoker_multi/mit-b3-finetuned-tmeTCGA-60-lr00001-s512-20x768/mask_cws/NS003-La.svs/Da1.png\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 20:36:24.640979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "2024-03-11 20:36:24.990698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-03-11 20:36:25.045642: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7641a6187e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-11 20:36:25.045679: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-03-11 20:36:25.045691: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-03-11 20:36:25.610600: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:543] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.8\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2024-03-11 20:36:25.686940: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 12s - 12s/epoch - 4s/step\n",
      "3/3 - 2s - 2s/epoch - 797ms/step\n",
      "3/3 - 2s - 2s/epoch - 800ms/step\n",
      "3/3 - 2s - 2s/epoch - 803ms/step\n",
      "3/3 - 2s - 2s/epoch - 808ms/step\n",
      "3/3 - 2s - 2s/epoch - 813ms/step\n",
      "3/3 - 2s - 2s/epoch - 810ms/step\n",
      "3/3 - 2s - 2s/epoch - 812ms/step\n",
      "3/3 - 2s - 2s/epoch - 818ms/step\n",
      "3/3 - 2s - 2s/epoch - 813ms/step\n",
      "3/3 - 2s - 2s/epoch - 825ms/step\n",
      "3/3 - 2s - 2s/epoch - 820ms/step\n",
      "3/3 - 2s - 2s/epoch - 827ms/step\n",
      "3/3 - 2s - 2s/epoch - 820ms/step\n",
      "3/3 - 3s - 3s/epoch - 837ms/step\n",
      "3/3 - 2s - 2s/epoch - 830ms/step\n",
      "3/3 - 2s - 2s/epoch - 831ms/step\n",
      "1/1 - 4s - 4s/epoch - 4s/step\n",
      "3/3 - 3s - 3s/epoch - 836ms/step\n",
      "3/3 - 2s - 2s/epoch - 833ms/step\n",
      "3/3 - 3s - 3s/epoch - 835ms/step\n",
      "3/3 - 3s - 3s/epoch - 842ms/step\n",
      "3/3 - 3s - 3s/epoch - 844ms/step\n",
      "3/3 - 3s - 3s/epoch - 846ms/step\n",
      "3/3 - 3s - 3s/epoch - 841ms/step\n",
      "3/3 - 3s - 3s/epoch - 836ms/step\n",
      "3/3 - 3s - 3s/epoch - 846ms/step\n",
      "3/3 - 3s - 3s/epoch - 843ms/step\n",
      "3/3 - 3s - 3s/epoch - 841ms/step\n",
      "3/3 - 3s - 3s/epoch - 839ms/step\n",
      "3/3 - 3s - 3s/epoch - 841ms/step\n",
      "3/3 - 3s - 3s/epoch - 841ms/step\n",
      "3/3 - 3s - 3s/epoch - 843ms/step\n",
      "3/3 - 3s - 3s/epoch - 846ms/step\n",
      "3/3 - 3s - 3s/epoch - 849ms/step\n",
      "3/3 - 3s - 3s/epoch - 842ms/step\n",
      "3/3 - 3s - 3s/epoch - 840ms/step\n",
      "3/3 - 3s - 3s/epoch - 855ms/step\n",
      "3/3 - 3s - 3s/epoch - 860ms/step\n",
      "3/3 - 3s - 3s/epoch - 860ms/step\n",
      "3/3 - 3s - 3s/epoch - 858ms/step\n",
      "3/3 - 3s - 3s/epoch - 854ms/step\n",
      "3/3 - 3s - 3s/epoch - 856ms/step\n",
      "3/3 - 3s - 3s/epoch - 854ms/step\n",
      "3/3 - 3s - 3s/epoch - 860ms/step\n",
      "3/3 - 3s - 3s/epoch - 854ms/step\n",
      "3/3 - 3s - 3s/epoch - 850ms/step\n",
      "3/3 - 3s - 3s/epoch - 855ms/step\n",
      "3/3 - 3s - 3s/epoch - 851ms/step\n",
      "1/1 - 2s - 2s/epoch - 2s/step\n",
      "3/3 - 3s - 3s/epoch - 864ms/step\n",
      "3/3 - 3s - 3s/epoch - 864ms/step\n",
      "3/3 - 3s - 3s/epoch - 853ms/step\n",
      "3/3 - 3s - 3s/epoch - 858ms/step\n",
      "3/3 - 3s - 3s/epoch - 855ms/step\n",
      "3/3 - 3s - 3s/epoch - 858ms/step\n",
      "3/3 - 3s - 3s/epoch - 862ms/step\n",
      "3/3 - 3s - 3s/epoch - 851ms/step\n",
      "3/3 - 3s - 3s/epoch - 863ms/step\n",
      "3/3 - 3s - 3s/epoch - 857ms/step\n",
      "3/3 - 3s - 3s/epoch - 851ms/step\n",
      "3/3 - 3s - 3s/epoch - 861ms/step\n",
      "3/3 - 3s - 3s/epoch - 866ms/step\n",
      "3/3 - 3s - 3s/epoch - 871ms/step\n",
      "3/3 - 3s - 3s/epoch - 867ms/step\n",
      "3/3 - 3s - 3s/epoch - 862ms/step\n",
      "3/3 - 3s - 3s/epoch - 868ms/step\n",
      "3/3 - 3s - 3s/epoch - 864ms/step\n",
      "3/3 - 3s - 3s/epoch - 873ms/step\n",
      "3/3 - 3s - 3s/epoch - 864ms/step\n",
      "3/3 - 3s - 3s/epoch - 863ms/step\n",
      "3/3 - 3s - 3s/epoch - 868ms/step\n",
      "3/3 - 3s - 3s/epoch - 863ms/step\n",
      "3/3 - 3s - 3s/epoch - 869ms/step\n",
      "3/3 - 3s - 3s/epoch - 879ms/step\n",
      "3/3 - 3s - 3s/epoch - 865ms/step\n",
      "3/3 - 3s - 3s/epoch - 867ms/step\n",
      "3/3 - 3s - 3s/epoch - 863ms/step\n",
      "3/3 - 3s - 3s/epoch - 863ms/step\n",
      "3/3 - 3s - 3s/epoch - 866ms/step\n",
      "3/3 - 3s - 3s/epoch - 867ms/step\n",
      "1/1 - 2s - 2s/epoch - 2s/step\n",
      "3/3 - 3s - 3s/epoch - 860ms/step\n",
      "3/3 - 3s - 3s/epoch - 860ms/step\n",
      "3/3 - 3s - 3s/epoch - 864ms/step\n",
      "3/3 - 3s - 3s/epoch - 860ms/step\n",
      "3/3 - 3s - 3s/epoch - 868ms/step\n",
      "3/3 - 3s - 3s/epoch - 860ms/step\n",
      "3/3 - 3s - 3s/epoch - 860ms/step\n",
      "3/3 - 3s - 3s/epoch - 862ms/step\n",
      "3/3 - 3s - 3s/epoch - 858ms/step\n",
      "3/3 - 3s - 3s/epoch - 865ms/step\n",
      "3/3 - 3s - 3s/epoch - 872ms/step\n",
      "3/3 - 3s - 3s/epoch - 862ms/step\n",
      "3/3 - 3s - 3s/epoch - 861ms/step\n",
      "3/3 - 3s - 3s/epoch - 859ms/step\n",
      "3/3 - 3s - 3s/epoch - 856ms/step\n",
      "3/3 - 3s - 3s/epoch - 869ms/step\n",
      "3/3 - 3s - 3s/epoch - 865ms/step\n",
      "3/3 - 3s - 3s/epoch - 863ms/step\n",
      "3/3 - 3s - 3s/epoch - 864ms/step\n",
      "3/3 - 3s - 3s/epoch - 859ms/step\n",
      "3/3 - 3s - 3s/epoch - 851ms/step\n",
      "3/3 - 3s - 3s/epoch - 852ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import platform\n",
    "import math\n",
    "from glob import glob\n",
    "from transformers import TFAutoModelForSemanticSegmentation\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Loss function\n",
    "\n",
    "\n",
    "def to_categorical_mask(multi_label, nClasses):\n",
    "    categorical_mask = np.zeros((multi_label.shape[0], multi_label.shape[1], nClasses))\n",
    "    for c in range(nClasses):\n",
    "        categorical_mask[:, :, c] = (multi_label == c).astype('float')\n",
    "    return categorical_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#openCV: BGR\n",
    "class_colors = [(0, 0, 0), (0, 255, 0), (255, 0, 255), (0, 0, 128), (0, 255, 255), (0, 0, 255), (255, 0, 0)]\n",
    "class_colors4 = [(0, 0, 0), (255, 255, 0), (255, 255, 255), (128, 0, 0)]\n",
    "class_colors5 = [(0, 0, 0), (255, 0, 0), (255, 0, 255), (0, 0, 128), (0, 255, 255), (0, 0, 255)]\n",
    "class_colors2 = [(0, 0, 0), (255, 255, 255)]\n",
    "class_colors6 = [(0, 0, 0), (0, 255, 0), (255, 0, 255), (0, 0, 128), (255, 255, 0), (0, 128, 128)]\n",
    "class_colors_tcga = [(0, 0, 0), (0, 0, 128), (0, 255, 255), (0, 0, 255),(255, 0, 255),(0, 128, 128)]\n",
    "class_colors8 = [(0, 0, 0), (0, 0, 128), (0, 255, 255), (0, 0, 255),(255, 0, 255),(0, 128, 128), (255, 255, 0), (255, 0, 0)]\n",
    "\n",
    "# tumor\t1\n",
    "# stroma\t2\n",
    "# lymphocytic_infiltrate\t3\n",
    "# necrosis_or_debris\t4\n",
    "# fat\t5\n",
    "\n",
    "#class_colors3 = [(0, 0, 0),  (0, 0, 128), (113, 113, 113)]\n",
    "#class_colorsOther = [(0, 0, 0), (0, 255, 0), (255, 0, 255), (255, 0, 0), (0, 255, 255), (0, 0, 255)]\n",
    "\n",
    "def get_colored_segmentation_image(seg_arr, n_classes, colors=class_colors5):\n",
    "    output_height = seg_arr.shape[0]\n",
    "    output_width = seg_arr.shape[1]\n",
    "\n",
    "    seg_img = np.zeros((output_height, output_width, 3))\n",
    "\n",
    "    for c in range(n_classes):\n",
    "        seg_arr_c = seg_arr[:, :] == c\n",
    "        seg_img[:, :, 0] += ((seg_arr_c)*(colors[c][0])).astype('uint8')\n",
    "        seg_img[:, :, 1] += ((seg_arr_c)*(colors[c][1])).astype('uint8')\n",
    "        seg_img[:, :, 2] += ((seg_arr_c)*(colors[c][2])).astype('uint8')\n",
    "\n",
    "    return seg_img\n",
    "\n",
    "\n",
    "target_image = np.float32(cv2.cvtColor(cv2.imread('target_gp.jpg'), cv2.COLOR_BGR2RGB)) / 255.0\n",
    "target_lab = cv2.cvtColor(target_image, cv2.COLOR_RGB2Lab)\n",
    "mt = np.mean(target_lab, axis=(0, 1))\n",
    "stdt = np.std(target_lab, axis=(0, 1))\n",
    "def pre_process_images(image, mt=mt, stdt=stdt):\n",
    "    image = np.float32(image) / 255.0\n",
    "    if np.any(image):\n",
    "        image = norm_reinhard(image, mt, stdt)\n",
    "    feat = 255.0 * image\n",
    "    feat[feat < 0.0] = 0.0\n",
    "    feat[feat > 255.0] = 255.0\n",
    "    feat = np.round(feat)\n",
    "    return feat\n",
    "\n",
    "def norm_reinhard(source_image, mt, stdt):\n",
    "    source_lab = cv2.cvtColor(source_image, cv2.COLOR_RGB2Lab)\n",
    "    ms = np.mean(source_lab, axis=(0, 1))\n",
    "    stds = np.std(source_lab, axis=(0, 1))\n",
    "    if np.sum(stds)<=5:\n",
    "        norm_image = source_image\n",
    "    else:\n",
    "        norm_lab = np.copy(source_lab)\n",
    "        norm_lab[:, :, 0] = ((norm_lab[:, :, 0] - ms[0]) * (stdt[0] / stds[0])) + mt[0]\n",
    "        norm_lab[:, :, 1] = ((norm_lab[:, :, 1] - ms[1]) * (stdt[1] / stds[1])) + mt[1]\n",
    "        norm_lab[:, :, 2] = ((norm_lab[:, :, 2] - ms[2]) * (stdt[2] / stds[2])) + mt[2]\n",
    "        norm_image = cv2.cvtColor(norm_lab, cv2.COLOR_Lab2RGB)\n",
    "    return norm_image\n",
    "\n",
    "class Patches:\n",
    "    def __init__(self, img_patch_h, img_patch_w, stride_h=384, stride_w=384, label_patch_h=None, label_patch_w=None):\n",
    "        assert img_patch_h > 0, 'Height of Image Patch should be greater than 0'\n",
    "        assert img_patch_w > 0, 'Width of Image Patch should be greater than 0'\n",
    "        assert label_patch_h > 0, 'Height of Label Patch should be greater than 0'\n",
    "        assert label_patch_w > 0, 'Width of Label Patch should be greater than 0'\n",
    "        assert img_patch_h >= label_patch_h, 'Height of Image Patch should be greater or equal to Label Patch'\n",
    "        assert img_patch_w >= label_patch_w, 'Width of Image Patch should be greater or equal to Label Patch'\n",
    "        assert stride_h > 0, 'Stride should be greater than 0'\n",
    "        assert stride_w > 0, 'Stride should be greater than 0'\n",
    "        assert stride_h <= label_patch_h, 'Row Stride should be less than or equal to Label Patch Height'\n",
    "        assert stride_w <= label_patch_w, 'Column Stride should be less than or equal to Label Patch Width'\n",
    "        self.img_patch_h = img_patch_h\n",
    "        self.img_patch_w = img_patch_w\n",
    "        self.stride_h = stride_h\n",
    "        self.stride_w = stride_w\n",
    "        self.label_patch_h = label_patch_h\n",
    "        self.label_patch_w = label_patch_w\n",
    "        self.img_h = None\n",
    "        self.img_w = None\n",
    "        self.img_d = None\n",
    "        self.num_patches_img = None\n",
    "        self.num_patches_img_h = None\n",
    "        self.num_patches_img_w = None\n",
    "        self.label_diff_pad_h = 0\n",
    "        self.label_diff_pad_w = 0\n",
    "        self.pad_h = 0\n",
    "        self.pad_w = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def read_image(input_str):\n",
    "        image = np.array(Image.open(input_str))\n",
    "        return image\n",
    "\n",
    "    def update_variables(self, image):\n",
    "        self.img_h = np.size(image, 0)\n",
    "        self.img_w = np.size(image, 1)\n",
    "        self.img_d = np.size(image, 2)\n",
    "\n",
    "    def extract_patches_img_label(self, input_img_value):\n",
    "        if type(input_img_value) == str:\n",
    "            image = self.read_image(input_img_value)\n",
    "        elif type(input_img_value) == np.ndarray:\n",
    "            image = input_img_value\n",
    "        else:\n",
    "            raise Exception('Please input correct image path or numpy array')\n",
    "        self.update_variables(image)\n",
    "\n",
    "\n",
    "        img_patch_h = self.img_patch_h\n",
    "        img_patch_w = self.img_patch_w\n",
    "\n",
    "        stride_h = self.stride_h\n",
    "        stride_w = self.stride_w\n",
    "\n",
    "        if image.shape[0] < img_patch_h:\n",
    "            self.pad_h = img_patch_h - image.shape[0]\n",
    "        else:\n",
    "            self.pad_h = 0\n",
    "\n",
    "        if image.shape[1] < img_patch_w:\n",
    "            self.pad_w = img_patch_w - image.shape[1]\n",
    "        else:\n",
    "            self.pad_w = 0\n",
    "\n",
    "        image = np.lib.pad(image, ((0, self.pad_h), (0, self.pad_w), (0, 0)), 'constant', constant_values=0)\n",
    "        #image = np.lib.pad(image, ((self.pad_h, self.pad_h), (self.pad_w, self.pad_w), (0, 0)),'symmetric')\n",
    "        #label = np.lib.pad(label, ((self.pad_h, self.pad_h), (self.pad_w, self.pad_w)), 'symmetric')\n",
    "\n",
    "        self.update_variables(image)\n",
    "\n",
    "        img_h = self.img_h\n",
    "        img_w = self.img_w\n",
    "        #print(img_h, img_w)\n",
    "\n",
    "        self.num_patches_img_h = math.ceil((img_h - img_patch_h) / stride_h + 1)\n",
    "        self.num_patches_img_w = math.ceil(((img_w - img_patch_w) / stride_w + 1))\n",
    "        num_patches_img = self.num_patches_img_h*self.num_patches_img_w\n",
    "        self.num_patches_img = num_patches_img\n",
    "        iter_tot = 0\n",
    "        img_patches = np.zeros((num_patches_img, img_patch_h, img_patch_w, image.shape[2]), dtype=image.dtype)\n",
    "        #label_patches = np.zeros((num_patches_img, label_patch_h, label_patch_w), dtype=image.dtype)\n",
    "        for h in range(int(math.ceil((img_h - img_patch_h) / stride_h + 1))):\n",
    "            for w in range(int(math.ceil((img_w - img_patch_w) / stride_w + 1))):\n",
    "                start_h = h * stride_h\n",
    "                end_h = (h * stride_h) + img_patch_h\n",
    "                start_w = w * stride_w\n",
    "                end_w = (w * stride_w) + img_patch_w\n",
    "                if end_h > img_h:\n",
    "                    start_h = img_h - img_patch_h\n",
    "                    end_h = img_h\n",
    "\n",
    "                if end_w > img_w:\n",
    "                    start_w = img_w - img_patch_w\n",
    "                    end_w = img_w\n",
    "\n",
    "\n",
    "                img_patches[iter_tot, :, :, :] = image[start_h:end_h, start_w:end_w, :]\n",
    "                #label_patches[iter_tot, :, :] = label[start_h:end_h, start_w:end_w]\n",
    "                iter_tot += 1\n",
    "\n",
    "        return img_patches\n",
    "\n",
    "\n",
    "    def merge_patches(self, patches):\n",
    "        img_h = self.img_h\n",
    "        img_w = self.img_w\n",
    "        img_patch_h = self.img_patch_h\n",
    "        img_patch_w = self.img_patch_w\n",
    "        label_patch_h = self.label_patch_h\n",
    "        label_patch_w = self.label_patch_w\n",
    "        stride_h = self.stride_h\n",
    "        stride_w = self.stride_w\n",
    "        num_patches_img = self.num_patches_img\n",
    "        assert num_patches_img == patches.shape[0], 'Number of Patches do not match'\n",
    "        #assert img_patch_h == patches.shape[1] or label_patch_h == patches.shape[1], 'Height of Patch does not match'\n",
    "        #assert img_patch_w == patches.shape[2] or label_patch_w == patches.shape[2], 'Width of Patch does not match'\n",
    "        # label = 0\n",
    "        # if label_patch_h == patches.shape[1] and label_patch_w == patches.shape[2]:\n",
    "        #     label = 1\n",
    "        image = np.zeros((img_h, img_w, patches.shape[3]), dtype=float)\n",
    "        sum_c = np.zeros((img_h, img_w, patches.shape[3]), dtype=float)\n",
    "        iter_tot = 0\n",
    "        for h in range(int(math.ceil((img_h - img_patch_h) / stride_h + 1))):\n",
    "            for w in range(int(math.ceil((img_w - img_patch_w) / stride_w + 1))):\n",
    "                start_h = h * stride_h\n",
    "                end_h = (h * stride_h) + img_patch_h\n",
    "                start_w = w * stride_w\n",
    "                end_w = (w * stride_w) + img_patch_w\n",
    "                if end_h > img_h:\n",
    "                    start_h = img_h - img_patch_h\n",
    "                    end_h = img_h\n",
    "\n",
    "                if end_w > img_w:\n",
    "                    start_w = img_w - img_patch_w\n",
    "                    end_w = img_w\n",
    "\n",
    "                if self.label_diff_pad_h == 0 and self.label_diff_pad_w == 0:\n",
    "                    image[start_h:end_h, start_w:end_w, :] +=cv2.resize(patches[iter_tot, :, :,:], (img_patch_h, img_patch_w))\n",
    "                    sum_c[start_h:end_h, start_w:end_w, :] += 1.0\n",
    "                else:\n",
    "                    image[\n",
    "                        start_h+self.label_diff_pad_h:start_h + label_patch_h + self.label_diff_pad_h,\n",
    "                        start_w+self.label_diff_pad_w:start_w + label_patch_w + self.label_diff_pad_w] += \\\n",
    "                        patches[iter_tot, :, :]\n",
    "                    sum_c[\n",
    "                        start_h+self.label_diff_pad_h:start_h + label_patch_h + self.label_diff_pad_h,\n",
    "                        start_w+self.label_diff_pad_w:start_w + label_patch_w + self.label_diff_pad_w] += 1.0\n",
    "                iter_tot += 1\n",
    "\n",
    "        if self.pad_h != 0 and self.pad_w != 0:\n",
    "            sum_c = sum_c[:-self.pad_h, :-self.pad_w, :]\n",
    "            image = image[:-self.pad_h, :-self.pad_w, :]\n",
    "\n",
    "        if self.pad_h == 0 and self.pad_w != 0:\n",
    "            sum_c = sum_c[:, :-self.pad_w, :]\n",
    "            image = image[:, :-self.pad_w, :]\n",
    "\n",
    "        if self.pad_h != 0 and self.pad_w == 0:\n",
    "            sum_c = sum_c[:-self.pad_h, :, :]\n",
    "            image = image[:-self.pad_h, :, :]\n",
    "\n",
    "        # sum_c = sum_c[self.pad_h:-self.pad_h, self.pad_w:-self.pad_w, :]\n",
    "        # image = image[self.pad_h:-self.pad_h, self.pad_w:-self.pad_w, :]\n",
    "        assert (np.min(sum_c) >= 1.0)\n",
    "        image = np.divide(image, sum_c)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "#segformer\n",
    "model_checkpoint = '/rsrch5/home/trans_mol_path/xpan7/pipelines/TMEseg_tcga/model/mit-b3-finetuned-tmeTCGA-60-lr00001-s512-20x768'\n",
    "model = TFAutoModelForSemanticSegmentation.from_pretrained(model_checkpoint)\n",
    "save_dir = '/rsrch6/home/trans_mol_path/yuan_lab/TIER2/anthracosis/never_smoker_multi/mit-b3-finetuned-tmeTCGA-60-lr00001-s512-20x768/mask_cws'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "datapath = '/rsrch6/home/trans_mol_path/yuan_lab/TIER2/anthracosis/never_smoker_multi/1_cws_tiling'\n",
    "files = sorted(glob(os.path.join(datapath, '*.svs')))[10:]\n",
    "patch_size = 512\n",
    "for file in files:\n",
    "    file_name = os.path.basename(file)\n",
    "    print(file_name)\n",
    "    test_img_dir = os.path.join(datapath, file_name)\n",
    "\n",
    "    save_dir_file = os.path.join(save_dir, file_name)\n",
    "    if not os.path.exists(save_dir_file):\n",
    "        os.makedirs(save_dir_file)\n",
    "\n",
    "    imgs = sorted(glob(os.path.join(test_img_dir, 'Da*')))\n",
    "    for im_f in imgs:\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        img_name = os.path.splitext(os.path.basename(im_f))[0]\n",
    "        if not os.path.exists(os.path.join(save_dir_file, img_name + '.png')):\n",
    "            testImgc = np.array(Image.open(im_f))\n",
    "            #testImgc = pre_process_images(np.array(Image.open(im_f)))\n",
    "            patch_obj = Patches(img_patch_h=patch_size, img_patch_w=patch_size, stride_h=192, stride_w=192, label_patch_h=patch_size,\n",
    "                                label_patch_w=patch_size)\n",
    "\n",
    "            testData_c = patch_obj.extract_patches_img_label(testImgc)\n",
    "            testData_c = testData_c.astype(np.float32)\n",
    "            testData_c = testData_c / 255.0\n",
    "            testData_c = tf.transpose(testData_c, (0, 3, 1, 2))\n",
    "\n",
    "            outData = model.predict(testData_c, verbose=2)\n",
    "            logit_temp = np.array(tf.transpose(outData.logits, (0, 2, 3, 1)))\n",
    "            merge_output = patch_obj.merge_patches(logit_temp)\n",
    "            merge_output = merge_output.argmax(axis=2)\n",
    "\n",
    "            seg_mask = get_colored_segmentation_image(merge_output, 8, colors=class_colors8)\n",
    "            seg_mask = cv2.resize(seg_mask, (testImgc.shape[1], testImgc.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            cv2.imwrite(os.path.join(save_dir_file, img_name + '.png'), seg_mask)\n",
    "            tf.keras.backend.clear_session()\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "        else:\n",
    "            print('Already Processed %s\\n' % os.path.join(save_dir_file, img_name + '.png'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998ed5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da9306d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
